<h1 align="center" id="title">Chat with PDF using LLM (React, FastAPI & Langchain)</h1>

<h2>üöÄ Demo</h2>
Deployement Link : https://muku-chat-pdf.netlify.app/
<br />
Demo Video Link : https://drive.google.com/file/d/1Ubb_VlEEHobux18xwI7IpVSVqvbzEH_0/view?usp=sharing


<h2>üõ†Ô∏è Installation Steps:</h2>

<p>1. First clone the project</p>

<p>2. Change to the frontend directory</p>

```
cd frontend
```

<p>3. Install frontend dependencies:</p>

```
npm install
```

<p>4. Start the frontend development server on localhost:5173</p>

```
npm run dev
```

<p>5. Change to the backend directory</p>

```
cd ../backend
```

<p>6. Create and activate a virtual environment (if not already created):</p>

```
python3 -m venv env source env/bin/activate
```

<p>7. Install backend dependencies:</p>

```
pip install -r requirements.txt
```

<p>8. Start the backend server at localhost:8000</p>

```
python3 run.py
```

  
  
<h2>üíª Built with</h2>

Technologies used in the project:

Frontend
*   React
*   Typescript
*   Tailwind
*   Vite

Backend
*   FastAPI
*   Langchain
*   Postgres
*   Gemini LLM : As my open ai api credits were exhausted
*   S3 for storing pdfs